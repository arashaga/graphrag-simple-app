10:04:24,90 graphrag.config.read_dotenv INFO Loading pipeline .env file
10:04:24,103 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 32",
        "type": "azure_openai_chat",
        "model": "gpt-4o-mini",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://eastus-openai-arash.openai.azure.com/",
        "api_version": "2024-02-15-preview",
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": "gpt-4o-mini",
        "model_supports_json": true,
        "tokens_per_minute": 150000,
        "requests_per_minute": 900,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "./data",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_embedding",
            "model": "text-embedding-3-large",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://eastus-openai-arash.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "text-embedding-3-large",
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://eastus-openai-arash.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o-mini",
            "model_supports_json": true,
            "tokens_per_minute": 150000,
            "requests_per_minute": 900,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://eastus-openai-arash.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o-mini",
            "model_supports_json": true,
            "tokens_per_minute": 150000,
            "requests_per_minute": 900,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://eastus-openai-arash.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o-mini",
            "model_supports_json": true,
            "tokens_per_minute": 150000,
            "requests_per_minute": 900,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 32",
            "type": "azure_openai_chat",
            "model": "gpt-4o-mini",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://eastus-openai-arash.openai.azure.com/",
            "api_version": "2024-02-15-preview",
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": "gpt-4o-mini",
            "model_supports_json": true,
            "tokens_per_minute": 150000,
            "requests_per_minute": 900,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
10:04:24,129 graphrag.index.create_pipeline_config INFO skipping workflows 
10:04:24,130 graphrag.index.run INFO Running pipeline
10:04:24,130 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at data\output\20240827-100424\artifacts
10:04:24,131 graphrag.index.input.load_input INFO loading input from root_dir=input
10:04:24,131 graphrag.index.input.load_input INFO using file storage for input
10:04:24,132 graphrag.index.storage.file_pipeline_storage INFO search data\input for files matching .*\.txt$
10:04:24,133 graphrag.index.input.text INFO found text files from input, found [('proj_2025.txt', {})]
10:04:24,151 graphrag.index.input.text INFO Found 1 files, loading 1
10:04:24,152 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
10:04:24,152 graphrag.index.run INFO Final # of rows loaded: 1
10:04:24,257 graphrag.index.run INFO Running workflow: create_base_text_units...
10:04:24,257 graphrag.index.run INFO dependencies for create_base_text_units: []
10:04:24,260 datashaper.workflow.workflow INFO executing verb orderby
10:04:24,263 datashaper.workflow.workflow INFO executing verb zip
10:04:24,265 datashaper.workflow.workflow INFO executing verb aggregate_override
10:04:24,268 datashaper.workflow.workflow INFO executing verb chunk
10:04:24,737 datashaper.workflow.workflow INFO executing verb select
10:04:24,739 datashaper.workflow.workflow INFO executing verb unroll
10:04:24,744 datashaper.workflow.workflow INFO executing verb rename
10:04:24,748 datashaper.workflow.workflow INFO executing verb genid
10:04:24,774 datashaper.workflow.workflow INFO executing verb unzip
10:04:24,779 datashaper.workflow.workflow INFO executing verb copy
10:04:24,782 datashaper.workflow.workflow INFO executing verb filter
10:04:24,809 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
10:04:24,965 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
10:04:24,966 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
10:04:24,966 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
10:04:24,992 datashaper.workflow.workflow INFO executing verb entity_extract
10:04:25,9 graphrag.llm.openai.create_openai_client INFO Creating Azure OpenAI client api_base=https://eastus-openai-arash.openai.azure.com, deployment_name=gpt-4o-mini
10:04:25,216 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o-mini: TPM=150000, RPM=900
10:04:25,217 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o-mini: 25
10:04:36,60 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:36,64 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 9.437999999849126. input_tokens=34, output_tokens=798
10:04:36,76 datashaper.workflow.workflow INFO executing verb merge_graphs
10:04:36,547 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
10:04:36,692 graphrag.index.run INFO Running workflow: create_summarized_entities...
10:04:36,692 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
10:04:36,693 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
10:04:36,713 datashaper.workflow.workflow INFO executing verb summarize_descriptions
10:04:38,399 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:38,409 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9069999998901039. input_tokens=224, output_tokens=62
10:04:39,147 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:39,151 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6410000000614673. input_tokens=173, output_tokens=53
10:04:39,304 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:39,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.702999999979511. input_tokens=337, output_tokens=152
10:04:39,314 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:39,318 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0940000000409782. input_tokens=178, output_tokens=61
10:04:41,90 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:41,92 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.875. input_tokens=292, output_tokens=102
10:04:41,284 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
10:04:41,447 graphrag.index.run INFO Running workflow: create_base_entity_graph...
10:04:41,447 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
10:04:41,448 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
10:04:41,470 datashaper.workflow.workflow INFO executing verb cluster_graph
10:04:44,109 datashaper.workflow.workflow INFO executing verb select
10:04:44,119 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
10:04:44,388 graphrag.index.run INFO Running workflow: create_final_entities...
10:04:44,388 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
10:04:44,388 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:04:44,437 datashaper.workflow.workflow INFO executing verb unpack_graph
10:04:45,629 datashaper.workflow.workflow INFO executing verb rename
10:04:45,635 datashaper.workflow.workflow INFO executing verb select
10:04:45,643 datashaper.workflow.workflow INFO executing verb dedupe
10:04:45,650 datashaper.workflow.workflow INFO executing verb rename
10:04:45,655 datashaper.workflow.workflow INFO executing verb filter
10:04:45,700 datashaper.workflow.workflow INFO executing verb text_split
10:04:45,737 datashaper.workflow.workflow INFO executing verb drop
10:04:45,744 datashaper.workflow.workflow INFO executing verb merge
10:04:46,178 datashaper.workflow.workflow INFO executing verb text_embed
10:04:46,180 graphrag.llm.openai.create_openai_client INFO Creating Azure OpenAI client api_base=https://eastus-openai-arash.openai.azure.com, deployment_name=text-embedding-3-large
10:04:46,375 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-large: TPM=0, RPM=0
10:04:46,375 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-large: 25
10:04:46,564 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 4077 inputs via 4077 snippets using 255 batches. max_batch_size=16, max_tokens=8191
10:04:46,968 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:46,973 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:46,979 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:46,981 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:46,990 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:46,998 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,7 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,22 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,31 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,33 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,37 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,39 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,44 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,52 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,54 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,68 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,72 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,87 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,99 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,99 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,107 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5319999998901039. input_tokens=467, output_tokens=0
10:04:47,136 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,139 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,145 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5629999998491257. input_tokens=1079, output_tokens=0
10:04:47,173 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5939999998081475. input_tokens=533, output_tokens=0
10:04:47,201 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6090000001713634. input_tokens=434, output_tokens=0
10:04:47,234 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6569999998901039. input_tokens=1035, output_tokens=0
10:04:47,267 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,268 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,284 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.703999999910593. input_tokens=543, output_tokens=0
10:04:47,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7190000000409782. input_tokens=496, output_tokens=0
10:04:47,349 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.75. input_tokens=531, output_tokens=0
10:04:47,377 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7970000000204891. input_tokens=947, output_tokens=0
10:04:47,429 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,429 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,433 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8440000000409782. input_tokens=510, output_tokens=0
10:04:47,462 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=553, output_tokens=0
10:04:47,488 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8910000000614673. input_tokens=533, output_tokens=0
10:04:47,515 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9220000000204891. input_tokens=467, output_tokens=0
10:04:47,542 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9529999999795109. input_tokens=685, output_tokens=0
10:04:47,571 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0. input_tokens=520, output_tokens=0
10:04:47,599 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0. input_tokens=616, output_tokens=0
10:04:47,631 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.047000000020489. input_tokens=2023, output_tokens=0
10:04:47,676 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0939999998081475. input_tokens=1696, output_tokens=0
10:04:47,708 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1090000001713634. input_tokens=513, output_tokens=0
10:04:47,737 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.156999999890104. input_tokens=797, output_tokens=0
10:04:47,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1879999998491257. input_tokens=962, output_tokens=0
10:04:47,803 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,826 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.25. input_tokens=1214, output_tokens=0
10:04:47,855 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2660000000614673. input_tokens=460, output_tokens=0
10:04:47,883 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3129999998491257. input_tokens=2124, output_tokens=0
10:04:47,940 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:47,955 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.375. input_tokens=953, output_tokens=0
10:04:47,993 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8590000001713634. input_tokens=541, output_tokens=0
10:04:48,39 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7970000000204891. input_tokens=496, output_tokens=0
10:04:48,85 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,90 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8589999999385327. input_tokens=429, output_tokens=0
10:04:48,196 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.796000000089407. input_tokens=1340, output_tokens=0
10:04:48,224 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,224 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,229 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,251 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,280 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,329 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,332 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0620000001508743. input_tokens=788, output_tokens=0
10:04:48,364 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,364 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,365 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,365 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,366 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,366 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,366 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,370 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,372 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9680000001098961. input_tokens=1285, output_tokens=0
10:04:48,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.172000000020489. input_tokens=745, output_tokens=0
10:04:48,431 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,431 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,432 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,432 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,449 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,450 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,452 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7810000001918525. input_tokens=921, output_tokens=0
10:04:48,482 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,483 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,489 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,491 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8130000000819564. input_tokens=1101, output_tokens=0
10:04:48,524 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,528 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7350000001024455. input_tokens=518, output_tokens=0
10:04:48,556 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1559999999590218. input_tokens=1111, output_tokens=0
10:04:48,583 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5930000001098961. input_tokens=593, output_tokens=0
10:04:48,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9380000000819564. input_tokens=801, output_tokens=0
10:04:48,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7339999999385327. input_tokens=964, output_tokens=0
10:04:48,682 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,691 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,695 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7809999999590218. input_tokens=1075, output_tokens=0
10:04:48,730 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6099999998696148. input_tokens=830, output_tokens=0
10:04:48,757 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9530000002123415. input_tokens=1358, output_tokens=0
10:04:48,785 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.078999999910593. input_tokens=1238, output_tokens=0
10:04:48,811 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0160000000614673. input_tokens=832, output_tokens=0
10:04:48,837 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.172000000020489. input_tokens=819, output_tokens=0
10:04:48,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8129999998491257. input_tokens=625, output_tokens=0
10:04:48,915 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2189999998081475. input_tokens=1384, output_tokens=0
10:04:48,945 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,946 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:48,971 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2659999998286366. input_tokens=732, output_tokens=0
10:04:49,20 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2190000000409782. input_tokens=524, output_tokens=0
10:04:49,52 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0309999999590218. input_tokens=1055, output_tokens=0
10:04:49,84 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,93 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6869999999180436. input_tokens=1108, output_tokens=0
10:04:49,121 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9060000001918525. input_tokens=1111, output_tokens=0
10:04:49,149 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4850000001024455. input_tokens=968, output_tokens=0
10:04:49,197 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,208 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.296000000089407. input_tokens=781, output_tokens=0
10:04:49,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8900000001303852. input_tokens=1450, output_tokens=0
10:04:49,288 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,301 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8899999998975545. input_tokens=1331, output_tokens=0
10:04:49,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8900000001303852. input_tokens=667, output_tokens=0
10:04:49,375 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8900000001303852. input_tokens=700, output_tokens=0
10:04:49,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.75. input_tokens=760, output_tokens=0
10:04:49,451 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,462 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7970000000204891. input_tokens=656, output_tokens=0
10:04:49,499 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,503 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,523 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5629999998491257. input_tokens=706, output_tokens=0
10:04:49,559 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,595 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7189999998081475. input_tokens=820, output_tokens=0
10:04:49,621 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,637 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,655 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,678 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5779999999795109. input_tokens=889, output_tokens=0
10:04:49,710 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,711 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,714 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,731 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5470000000204891. input_tokens=605, output_tokens=0
10:04:49,761 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,764 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8909999998286366. input_tokens=774, output_tokens=0
10:04:49,806 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,807 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,807 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,807 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,808 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,808 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,812 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,814 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2809999999590218. input_tokens=916, output_tokens=0
10:04:49,845 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,846 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,850 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,854 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,857 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.40699999989010394. input_tokens=732, output_tokens=0
10:04:49,891 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9220000000204891. input_tokens=805, output_tokens=0
10:04:49,923 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,924 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,937 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,938 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,939 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:49,945 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2810000001918525. input_tokens=569, output_tokens=0
10:04:49,976 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7809999999590218. input_tokens=563, output_tokens=0
10:04:50,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5780000002123415. input_tokens=826, output_tokens=0
10:04:50,43 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8589999999385327. input_tokens=645, output_tokens=0
10:04:50,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0. input_tokens=643, output_tokens=0
10:04:50,112 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,113 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,142 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2659999998286366. input_tokens=784, output_tokens=0
10:04:50,173 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7969999997876585. input_tokens=795, output_tokens=0
10:04:50,205 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,208 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6560000001918525. input_tokens=694, output_tokens=0
10:04:50,234 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5630000000819564. input_tokens=772, output_tokens=0
10:04:50,264 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3909999998286366. input_tokens=639, output_tokens=0
10:04:50,290 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5619999999180436. input_tokens=557, output_tokens=0
10:04:50,321 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2340000001713634. input_tokens=581, output_tokens=0
10:04:50,351 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4689999998081475. input_tokens=728, output_tokens=0
10:04:50,390 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,390 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,399 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,420 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1869999999180436. input_tokens=1033, output_tokens=0
10:04:50,450 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.171000000089407. input_tokens=1121, output_tokens=0
10:04:50,485 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8599999998696148. input_tokens=544, output_tokens=0
10:04:50,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0309999999590218. input_tokens=808, output_tokens=0
10:04:50,557 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8599999998696148. input_tokens=483, output_tokens=0
10:04:50,596 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2339999999385327. input_tokens=853, output_tokens=0
10:04:50,624 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=430, output_tokens=0
10:04:50,650 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.9690000000409782. input_tokens=929, output_tokens=0
10:04:50,694 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,700 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9060000001918525. input_tokens=628, output_tokens=0
10:04:50,729 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,746 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9060000001918525. input_tokens=864, output_tokens=0
10:04:50,774 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8910000000614673. input_tokens=641, output_tokens=0
10:04:50,801 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,817 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8910000000614673. input_tokens=553, output_tokens=0
10:04:50,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7650000001303852. input_tokens=435, output_tokens=0
10:04:50,916 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6559999999590218. input_tokens=669, output_tokens=0
10:04:50,943 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:50,954 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8430000001098961. input_tokens=784, output_tokens=0
10:04:50,986 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,2 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7340000001713634. input_tokens=502, output_tokens=0
10:04:51,59 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,64 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,79 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,148 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,159 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,185 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7970000000204891. input_tokens=745, output_tokens=0
10:04:51,212 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,215 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0939999998081475. input_tokens=730, output_tokens=0
10:04:51,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7030000002123415. input_tokens=740, output_tokens=0
10:04:51,274 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,276 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,276 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,277 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,277 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,280 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,280 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,281 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,282 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,283 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,283 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,283 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,284 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,286 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9690000000409782. input_tokens=676, output_tokens=0
10:04:51,331 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,332 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,332 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,335 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6400000001303852. input_tokens=616, output_tokens=0
10:04:51,372 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6870000001508743. input_tokens=630, output_tokens=0
10:04:51,422 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,428 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,452 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5930000001098961. input_tokens=727, output_tokens=0
10:04:51,492 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1099999998696148. input_tokens=829, output_tokens=0
10:04:51,524 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7190000000409782. input_tokens=495, output_tokens=0
10:04:51,553 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9529999999795109. input_tokens=698, output_tokens=0
10:04:51,581 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2340000001713634. input_tokens=725, output_tokens=0
10:04:51,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=645, output_tokens=0
10:04:51,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5309999999590218. input_tokens=855, output_tokens=0
10:04:51,684 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.297000000020489. input_tokens=1008, output_tokens=0
10:04:51,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4059999999590218. input_tokens=522, output_tokens=0
10:04:51,747 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,764 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,764 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,770 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.077999999979511. input_tokens=927, output_tokens=0
10:04:51,799 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6719999997876585. input_tokens=527, output_tokens=0
10:04:51,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.343000000109896. input_tokens=770, output_tokens=0
10:04:51,856 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9529999999795109. input_tokens=587, output_tokens=0
10:04:51,882 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8900000001303852. input_tokens=610, output_tokens=0
10:04:51,909 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,909 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:51,912 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3600000001024455. input_tokens=907, output_tokens=0
10:04:51,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9849999998696148. input_tokens=869, output_tokens=0
10:04:51,968 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1559999999590218. input_tokens=691, output_tokens=0
10:04:52,15 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9839999999385327. input_tokens=567, output_tokens=0
10:04:52,57 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.577999999979511. input_tokens=713, output_tokens=0
10:04:52,86 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,125 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9220000000204891. input_tokens=513, output_tokens=0
10:04:52,160 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8910000000614673. input_tokens=613, output_tokens=0
10:04:52,188 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9529999999795109. input_tokens=701, output_tokens=0
10:04:52,217 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,232 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9069999998901039. input_tokens=869, output_tokens=0
10:04:52,262 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8440000000409782. input_tokens=1004, output_tokens=0
10:04:52,304 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8910000000614673. input_tokens=582, output_tokens=0
10:04:52,355 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,355 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7650000001303852. input_tokens=641, output_tokens=0
10:04:52,412 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6569999998901039. input_tokens=729, output_tokens=0
10:04:52,458 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5150000001303852. input_tokens=579, output_tokens=0
10:04:52,503 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.45300000021234155. input_tokens=633, output_tokens=0
10:04:52,529 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,538 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,553 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,577 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,598 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,621 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9840000001713634. input_tokens=604, output_tokens=0
10:04:52,648 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,649 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,649 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6569999998901039. input_tokens=763, output_tokens=0
10:04:52,684 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6879999998491257. input_tokens=565, output_tokens=0
10:04:52,722 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,728 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6410000000614673. input_tokens=725, output_tokens=0
10:04:52,765 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,765 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,766 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,766 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,766 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,767 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,768 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,768 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,768 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,769 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,770 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,770 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,778 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,780 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5470000000204891. input_tokens=596, output_tokens=0
10:04:52,811 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=691, output_tokens=0
10:04:52,852 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,860 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,861 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,864 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5160000000614673. input_tokens=542, output_tokens=0
10:04:52,917 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2809999999590218. input_tokens=627, output_tokens=0
10:04:52,954 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,965 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:52,968 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.327999999979511. input_tokens=683, output_tokens=0
10:04:53,3 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5470000000204891. input_tokens=468, output_tokens=0
10:04:53,32 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=555, output_tokens=0
10:04:53,64 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.125. input_tokens=592, output_tokens=0
10:04:53,90 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7970000000204891. input_tokens=810, output_tokens=0
10:04:53,118 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8280000002123415. input_tokens=561, output_tokens=0
10:04:53,145 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3909999998286366. input_tokens=606, output_tokens=0
10:04:53,171 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5309999999590218. input_tokens=673, output_tokens=0
10:04:53,198 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.202999999979511. input_tokens=572, output_tokens=0
10:04:53,227 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2190000000409782. input_tokens=493, output_tokens=0
10:04:53,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0150000001303852. input_tokens=562, output_tokens=0
10:04:53,293 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8899999998975545. input_tokens=717, output_tokens=0
10:04:53,340 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8439999998081475. input_tokens=512, output_tokens=0
10:04:53,371 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,373 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,374 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,374 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,383 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.75. input_tokens=625, output_tokens=0
10:04:53,417 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6559999999590218. input_tokens=558, output_tokens=0
10:04:53,481 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8440000000409782. input_tokens=500, output_tokens=0
10:04:53,519 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5. input_tokens=684, output_tokens=0
10:04:53,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0149999998975545. input_tokens=570, output_tokens=0
10:04:53,593 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9220000000204891. input_tokens=577, output_tokens=0
10:04:53,622 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,638 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,642 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=633, output_tokens=0
10:04:53,670 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9529999999795109. input_tokens=445, output_tokens=0
10:04:53,697 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8590000001713634. input_tokens=690, output_tokens=0
10:04:53,723 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=524, output_tokens=0
10:04:53,776 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,776 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,793 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8439999998081475. input_tokens=658, output_tokens=0
10:04:53,850 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7809999999590218. input_tokens=889, output_tokens=0
10:04:53,885 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6720000000204891. input_tokens=588, output_tokens=0
10:04:53,912 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,931 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,935 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5629999998491257. input_tokens=756, output_tokens=0
10:04:53,973 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:53,984 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.093000000109896. input_tokens=767, output_tokens=0
10:04:54,29 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,44 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7649999998975545. input_tokens=559, output_tokens=0
10:04:54,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.796000000089407. input_tokens=500, output_tokens=0
10:04:54,110 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,115 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6720000000204891. input_tokens=621, output_tokens=0
10:04:54,151 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,155 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,156 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,158 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=526, output_tokens=0
10:04:54,191 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,192 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,192 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,192 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,193 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,193 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,194 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,199 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,201 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,205 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,206 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.46899999980814755. input_tokens=776, output_tokens=0
10:04:54,248 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,249 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,255 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5. input_tokens=605, output_tokens=0
10:04:54,287 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,288 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,302 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6719999997876585. input_tokens=657, output_tokens=0
10:04:54,337 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.047000000020489. input_tokens=474, output_tokens=0
10:04:54,380 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,381 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,387 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,389 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,389 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,396 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8440000000409782. input_tokens=555, output_tokens=0
10:04:54,434 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.5160000000614673. input_tokens=517, output_tokens=0
10:04:54,472 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0. input_tokens=425, output_tokens=0
10:04:54,503 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6560000001918525. input_tokens=705, output_tokens=0
10:04:54,535 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.953999999910593. input_tokens=436, output_tokens=0
10:04:54,564 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2809999999590218. input_tokens=540, output_tokens=0
10:04:54,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8439999998081475. input_tokens=592, output_tokens=0
10:04:54,620 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.297000000020489. input_tokens=514, output_tokens=0
10:04:54,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7659999998286366. input_tokens=512, output_tokens=0
10:04:54,692 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,701 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,704 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4840000001713634. input_tokens=695, output_tokens=0
10:04:54,734 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7029999999795109. input_tokens=666, output_tokens=0
10:04:54,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4379999998491257. input_tokens=475, output_tokens=0
10:04:54,789 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4689999998081475. input_tokens=571, output_tokens=0
10:04:54,818 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8440000000409782. input_tokens=474, output_tokens=0
10:04:54,846 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5619999999180436. input_tokens=648, output_tokens=0
10:04:54,893 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.156999999890104. input_tokens=537, output_tokens=0
10:04:54,935 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8599999998696148. input_tokens=682, output_tokens=0
10:04:54,968 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:54,977 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8279999999795109. input_tokens=480, output_tokens=0
10:04:55,7 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8900000001303852. input_tokens=647, output_tokens=0
10:04:55,34 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.406999999890104. input_tokens=492, output_tokens=0
10:04:55,61 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,91 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9059999999590218. input_tokens=530, output_tokens=0
10:04:55,133 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=539, output_tokens=0
10:04:55,180 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,193 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9059999999590218. input_tokens=484, output_tokens=0
10:04:55,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8599999998696148. input_tokens=544, output_tokens=0
10:04:55,265 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,270 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8909999998286366. input_tokens=434, output_tokens=0
10:04:55,313 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.625. input_tokens=643, output_tokens=0
10:04:55,401 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7350000001024455. input_tokens=480, output_tokens=0
10:04:55,441 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,441 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,449 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6400000001303852. input_tokens=596, output_tokens=0
10:04:55,495 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,495 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,514 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,517 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,527 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8440000000409782. input_tokens=710, output_tokens=0
10:04:55,563 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,568 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6879999998491257. input_tokens=575, output_tokens=0
10:04:55,602 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,607 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,625 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.75. input_tokens=593, output_tokens=0
10:04:55,661 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9850000001024455. input_tokens=688, output_tokens=0
10:04:55,689 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,690 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,692 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,703 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,704 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0310000001918525. input_tokens=522, output_tokens=0
10:04:55,737 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8440000000409782. input_tokens=516, output_tokens=0
10:04:55,768 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,768 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.625. input_tokens=677, output_tokens=0
10:04:55,821 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,822 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,823 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,823 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,827 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7650000001303852. input_tokens=695, output_tokens=0
10:04:55,863 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,869 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9060000001918525. input_tokens=481, output_tokens=0
10:04:55,913 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,913 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:55,917 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.25. input_tokens=1334, output_tokens=0
10:04:55,949 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9840000001713634. input_tokens=565, output_tokens=0
10:04:55,996 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7340000001713634. input_tokens=469, output_tokens=0
10:04:56,33 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,33 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,42 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.452999999979511. input_tokens=867, output_tokens=0
10:04:56,72 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4060000001918525. input_tokens=674, output_tokens=0
10:04:56,101 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0159999998286366. input_tokens=562, output_tokens=0
10:04:56,129 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6870000001508743. input_tokens=817, output_tokens=0
10:04:56,166 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,173 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,178 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8589999999385327. input_tokens=537, output_tokens=0
10:04:56,209 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.077999999979511. input_tokens=644, output_tokens=0
10:04:56,239 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.75. input_tokens=580, output_tokens=0
10:04:56,268 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3909999998286366. input_tokens=621, output_tokens=0
10:04:56,314 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6410000000614673. input_tokens=531, output_tokens=0
10:04:56,358 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4849999998696148. input_tokens=557, output_tokens=0
10:04:56,399 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,405 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.047000000020489. input_tokens=801, output_tokens=0
10:04:56,444 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=623, output_tokens=0
10:04:56,506 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,519 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,525 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9220000000204891. input_tokens=550, output_tokens=0
10:04:56,564 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4849999998696148. input_tokens=568, output_tokens=0
10:04:56,634 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9529999999795109. input_tokens=474, output_tokens=0
10:04:56,674 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,675 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,682 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0309999999590218. input_tokens=707, output_tokens=0
10:04:56,741 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,746 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9220000000204891. input_tokens=502, output_tokens=0
10:04:56,787 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0160000000614673. input_tokens=793, output_tokens=0
10:04:56,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8430000001098961. input_tokens=543, output_tokens=0
10:04:56,875 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,889 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6559999999590218. input_tokens=524, output_tokens=0
10:04:56,923 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7649999998975545. input_tokens=492, output_tokens=0
10:04:56,960 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,977 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:56,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.125. input_tokens=549, output_tokens=0
10:04:57,21 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,26 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.8600000001024455. input_tokens=511, output_tokens=0
10:04:57,61 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,66 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.297000000020489. input_tokens=541, output_tokens=0
10:04:57,116 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7029999999795109. input_tokens=522, output_tokens=0
10:04:57,151 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,164 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,179 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1719999997876585. input_tokens=469, output_tokens=0
10:04:57,206 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,227 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6099999998696148. input_tokens=445, output_tokens=0
10:04:57,250 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,253 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9370000001508743. input_tokens=489, output_tokens=0
10:04:57,286 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,290 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9839999999385327. input_tokens=525, output_tokens=0
10:04:57,331 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,332 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,338 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3589999999385327. input_tokens=500, output_tokens=0
10:04:57,376 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,378 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,386 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.875. input_tokens=555, output_tokens=0
10:04:57,431 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2660000000614673. input_tokens=629, output_tokens=0
10:04:57,481 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3130000000819564. input_tokens=601, output_tokens=0
10:04:57,553 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:57,565 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.047000000020489. input_tokens=570, output_tokens=0
10:04:57,606 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.0. input_tokens=403, output_tokens=0
10:04:57,638 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6089999999385327. input_tokens=571, output_tokens=0
10:04:57,676 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.327999999979511. input_tokens=562, output_tokens=0
10:04:57,723 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4059999999590218. input_tokens=413, output_tokens=0
10:04:58,242 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/text-embedding-3-large/embeddings?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:04:58,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 2.202999999979511. input_tokens=486, output_tokens=0
10:04:58,565 datashaper.workflow.workflow INFO executing verb drop
10:04:58,573 datashaper.workflow.workflow INFO executing verb filter
10:04:58,623 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
10:04:59,613 graphrag.index.run INFO Running workflow: create_final_nodes...
10:04:59,615 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
10:04:59,616 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:04:59,684 datashaper.workflow.workflow INFO executing verb layout_graph
10:05:06,245 datashaper.workflow.workflow INFO executing verb unpack_graph
10:05:08,908 datashaper.workflow.workflow INFO executing verb unpack_graph
10:05:11,368 datashaper.workflow.workflow INFO executing verb filter
10:05:11,710 datashaper.workflow.workflow INFO executing verb drop
10:05:11,735 datashaper.workflow.workflow INFO executing verb select
10:05:11,755 datashaper.workflow.workflow INFO executing verb rename
10:05:11,778 datashaper.workflow.workflow INFO executing verb convert
10:05:11,910 datashaper.workflow.workflow INFO executing verb join
10:05:11,981 datashaper.workflow.workflow INFO executing verb rename
10:05:11,991 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
10:05:12,303 graphrag.index.run INFO Running workflow: create_final_communities...
10:05:12,303 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
10:05:12,304 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:05:12,385 datashaper.workflow.workflow INFO executing verb unpack_graph
10:05:14,822 datashaper.workflow.workflow INFO executing verb unpack_graph
10:05:16,987 datashaper.workflow.workflow INFO executing verb aggregate_override
10:05:17,29 datashaper.workflow.workflow INFO executing verb join
10:05:17,240 datashaper.workflow.workflow INFO executing verb join
10:05:17,432 datashaper.workflow.workflow INFO executing verb concat
10:05:17,471 datashaper.workflow.workflow INFO executing verb filter
10:05:22,755 datashaper.workflow.workflow INFO executing verb aggregate_override
10:05:22,932 datashaper.workflow.workflow INFO executing verb join
10:05:22,965 datashaper.workflow.workflow INFO executing verb filter
10:05:23,107 datashaper.workflow.workflow INFO executing verb fill
10:05:23,139 datashaper.workflow.workflow INFO executing verb merge
10:05:23,367 datashaper.workflow.workflow INFO executing verb copy
10:05:23,395 datashaper.workflow.workflow INFO executing verb select
10:05:23,400 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
10:05:23,691 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
10:05:23,691 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
10:05:23,692 graphrag.index.run INFO read table from storage: create_final_entities.parquet
10:05:24,298 datashaper.workflow.workflow INFO executing verb select
10:05:24,332 datashaper.workflow.workflow INFO executing verb unroll
10:05:24,366 datashaper.workflow.workflow INFO executing verb aggregate_override
10:05:24,403 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
10:05:24,651 graphrag.index.run INFO Running workflow: create_final_relationships...
10:05:24,651 graphrag.index.run INFO dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
10:05:24,651 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
10:05:24,694 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
10:05:24,778 datashaper.workflow.workflow INFO executing verb unpack_graph
10:05:27,158 datashaper.workflow.workflow INFO executing verb filter
10:05:27,668 datashaper.workflow.workflow INFO executing verb rename
10:05:27,702 datashaper.workflow.workflow INFO executing verb filter
10:05:28,216 datashaper.workflow.workflow INFO executing verb drop
10:05:28,250 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
10:05:28,290 datashaper.workflow.workflow INFO executing verb convert
10:05:28,364 datashaper.workflow.workflow INFO executing verb convert
10:05:28,405 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
10:05:28,684 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
10:05:28,684 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
10:05:28,685 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
10:05:28,770 datashaper.workflow.workflow INFO executing verb select
10:05:28,811 datashaper.workflow.workflow INFO executing verb unroll
10:05:28,852 datashaper.workflow.workflow INFO executing verb aggregate_override
10:05:28,918 datashaper.workflow.workflow INFO executing verb select
10:05:28,922 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
10:05:29,172 graphrag.index.run INFO Running workflow: create_final_community_reports...
10:05:29,173 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
10:05:29,174 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
10:05:29,196 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
10:05:29,285 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
10:05:29,790 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
10:05:29,982 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
10:05:30,229 datashaper.workflow.workflow INFO executing verb prepare_community_reports
10:05:30,231 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=3 => 4077
10:05:30,435 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 4077
10:05:32,417 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 4077
10:05:34,166 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 4077
10:05:35,57 datashaper.workflow.workflow INFO executing verb create_community_reports
10:05:40,787 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:40,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.625. input_tokens=2162, output_tokens=558
10:05:41,574 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:41,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.468000000109896. input_tokens=2218, output_tokens=667
10:05:42,292 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:42,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.125. input_tokens=2233, output_tokens=791
10:05:42,584 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:42,586 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.359000000171363. input_tokens=2400, output_tokens=700
10:05:42,664 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:42,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.452999999979511. input_tokens=3700, output_tokens=820
10:05:42,976 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:42,979 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.797000000020489. input_tokens=3099, output_tokens=787
10:05:43,140 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:43,142 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.952999999979511. input_tokens=3223, output_tokens=711
10:05:43,552 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:43,554 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.452999999979511. input_tokens=2872, output_tokens=797
10:05:43,871 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:43,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.75. input_tokens=3686, output_tokens=942
10:05:44,345 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:44,346 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.202999999979511. input_tokens=7211, output_tokens=819
10:05:44,433 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:44,436 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.344000000040978. input_tokens=2652, output_tokens=711
10:05:44,468 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:44,471 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.311999999918044. input_tokens=4200, output_tokens=841
10:05:44,637 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:44,638 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.515999999828637. input_tokens=2595, output_tokens=749
10:05:45,282 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:45,284 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.141000000061467. input_tokens=2712, output_tokens=835
10:05:45,376 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:45,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.172000000020489. input_tokens=2871, output_tokens=805
10:05:45,622 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:45,624 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.390000000130385. input_tokens=3188, output_tokens=857
10:05:46,813 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:46,815 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.655999999959022. input_tokens=4178, output_tokens=734
10:05:47,378 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:47,380 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.203000000212342. input_tokens=4301, output_tokens=767
10:05:48,264 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:48,267 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:05:48,270 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.155999999959022. input_tokens=3212, output_tokens=1083
10:05:48,272 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.062999999849126. input_tokens=2111, output_tokens=631
10:06:00,378 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:00,380 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.625. input_tokens=2064, output_tokens=515
10:06:00,672 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:00,674 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.8899999998975545. input_tokens=2091, output_tokens=549
10:06:00,736 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:00,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.969000000040978. input_tokens=2427, output_tokens=805
10:06:00,856 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:00,858 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.202999999979511. input_tokens=2142, output_tokens=624
10:06:01,71 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:01,74 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.218000000109896. input_tokens=2317, output_tokens=613
10:06:01,157 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:01,158 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.438000000081956. input_tokens=2055, output_tokens=540
10:06:01,206 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:01,208 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.546000000089407. input_tokens=2216, output_tokens=663
10:06:01,252 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:01,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.593000000109896. input_tokens=2113, output_tokens=621
10:06:01,441 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:01,443 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.702999999979511. input_tokens=2119, output_tokens=634
10:06:01,590 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:01,592 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.890999999828637. input_tokens=2188, output_tokens=659
10:06:01,637 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:01,639 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.797000000020489. input_tokens=2347, output_tokens=677
10:06:01,827 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:01,829 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.109000000171363. input_tokens=2098, output_tokens=729
10:06:02,116 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:02,118 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.375. input_tokens=2149, output_tokens=772
10:06:02,198 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:02,200 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.5310000001918525. input_tokens=8018, output_tokens=769
10:06:02,691 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:02,692 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.905999999959022. input_tokens=2193, output_tokens=683
10:06:02,760 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:02,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.905999999959022. input_tokens=2253, output_tokens=748
10:06:03,127 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:03,129 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.281000000191852. input_tokens=4713, output_tokens=720
10:06:03,425 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:03,427 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.733999999938533. input_tokens=2986, output_tokens=724
10:06:03,585 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:03,586 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.765000000130385. input_tokens=2719, output_tokens=765
10:06:03,733 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:03,734 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.938000000081956. input_tokens=7415, output_tokens=832
10:06:03,948 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:03,951 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.125. input_tokens=2439, output_tokens=720
10:06:04,959 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:04,966 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.187000000150874. input_tokens=2440, output_tokens=782
10:06:06,761 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:06,761 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.030999999959022. input_tokens=2288, output_tokens=604
10:06:06,810 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:06,812 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.952999999979511. input_tokens=2118, output_tokens=640
10:06:07,132 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:07,134 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.765999999828637. input_tokens=2600, output_tokens=678
10:06:07,438 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:07,440 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.359999999869615. input_tokens=2089, output_tokens=577
10:06:07,584 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:07,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.984000000171363. input_tokens=2084, output_tokens=517
10:06:07,658 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:07,660 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.844000000040978. input_tokens=2134, output_tokens=719
10:06:07,679 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:07,681 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.530999999959022. input_tokens=2322, output_tokens=606
10:06:07,793 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:07,797 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.358999999938533. input_tokens=2084, output_tokens=622
10:06:08,850 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:08,988 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:08,989 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.281999999890104. input_tokens=2172, output_tokens=690
10:06:09,188 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.172000000020489. input_tokens=2610, output_tokens=811
10:06:09,556 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:09,557 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.969000000040978. input_tokens=2188, output_tokens=675
10:06:09,759 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:09,846 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:09,849 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.155999999959022. input_tokens=2401, output_tokens=692
10:06:10,84 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.905999999959022. input_tokens=3315, output_tokens=795
10:06:10,173 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:10,364 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:10,425 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.0469999997876585. input_tokens=2339, output_tokens=649
10:06:10,508 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:10,572 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:10,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.625. input_tokens=2576, output_tokens=846
10:06:11,111 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.375. input_tokens=2148, output_tokens=678
10:06:11,162 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:11,327 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:11,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.359000000171363. input_tokens=2324, output_tokens=703
10:06:11,369 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:11,469 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:11,471 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.265999999828637. input_tokens=2093, output_tokens=586
10:06:11,509 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:11,787 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.094000000040978. input_tokens=2434, output_tokens=674
10:06:12,193 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.390999999828637. input_tokens=2925, output_tokens=840
10:06:12,395 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:12,396 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.625. input_tokens=2558, output_tokens=721
10:06:12,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.734000000171363. input_tokens=5034, output_tokens=806
10:06:13,6 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.921999999787658. input_tokens=2068, output_tokens=634
10:06:13,234 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:13,580 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.281999999890104. input_tokens=2559, output_tokens=850
10:06:15,494 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:15,497 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.687000000150874. input_tokens=2891, output_tokens=822
10:06:15,633 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:15,748 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:15,749 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.984000000171363. input_tokens=2676, output_tokens=809
10:06:16,275 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.812999999849126. input_tokens=2512, output_tokens=813
10:06:17,222 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:17,224 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.561999999918044. input_tokens=2150, output_tokens=652
10:06:20,258 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:20,260 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.108999999938533. input_tokens=2199, output_tokens=664
10:06:21,408 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:21,410 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.3600000001024455. input_tokens=2172, output_tokens=687
10:06:22,702 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:22,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.5310000001918525. input_tokens=2031, output_tokens=379
10:06:25,16 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:25,19 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.0. input_tokens=2377, output_tokens=729
10:06:26,153 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:26,154 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.125. input_tokens=2201, output_tokens=672
10:06:27,131 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:27,133 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.093000000109896. input_tokens=2555, output_tokens=789
10:06:27,602 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:27,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.547000000020489. input_tokens=2236, output_tokens=659
10:06:29,775 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:29,777 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.313000000081956. input_tokens=2477, output_tokens=684
10:06:29,992 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:29,995 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.390000000130385. input_tokens=2045, output_tokens=659
10:06:30,43 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:30,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.577999999979511. input_tokens=2084, output_tokens=556
10:06:34,916 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:34,917 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.7189999998081475. input_tokens=2207, output_tokens=699
10:06:35,361 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:35,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.952999999979511. input_tokens=2195, output_tokens=707
10:06:35,856 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:35,859 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.327999999979511. input_tokens=2393, output_tokens=807
10:06:36,312 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:36,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.077999999979511. input_tokens=2802, output_tokens=788
10:06:38,215 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:38,562 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.327999999979511. input_tokens=2438, output_tokens=846
10:06:39,203 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:39,205 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.343000000109896. input_tokens=2390, output_tokens=672
10:06:39,396 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:39,398 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.625. input_tokens=2071, output_tokens=596
10:06:41,274 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:41,276 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.5. input_tokens=2242, output_tokens=697
10:06:46,376 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:46,378 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.640000000130385. input_tokens=2705, output_tokens=803
10:06:48,455 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:48,458 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.437000000150874. input_tokens=2258, output_tokens=621
10:06:51,339 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:51,342 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.265999999828637. input_tokens=3031, output_tokens=766
10:06:54,312 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:54,316 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.062999999849126. input_tokens=2216, output_tokens=743
10:06:54,518 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:54,798 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.625. input_tokens=2142, output_tokens=693
10:06:55,581 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:55,584 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 17.406000000191852. input_tokens=2546, output_tokens=801
10:06:57,506 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:57,509 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.858999999938533. input_tokens=2772, output_tokens=745
10:06:59,825 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:06:59,827 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 19.82799999997951. input_tokens=2214, output_tokens=738
10:07:00,756 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:00,758 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.312000000150874. input_tokens=2568, output_tokens=788
10:07:00,841 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:00,844 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.780999999959022. input_tokens=3005, output_tokens=756
10:07:01,113 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:01,115 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 16.094000000040978. input_tokens=2717, output_tokens=797
10:07:04,315 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:04,318 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 16.0. input_tokens=2795, output_tokens=655
10:07:04,732 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:04,734 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 20.813000000081956. input_tokens=2790, output_tokens=699
10:07:05,842 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:05,844 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.327999999979511. input_tokens=2472, output_tokens=730
10:07:06,623 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:06,796 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:06,996 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.547000000020489. input_tokens=2779, output_tokens=923
10:07:07,207 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:07,209 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.421000000089407. input_tokens=2677, output_tokens=720
10:07:07,746 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.202999999979511. input_tokens=2544, output_tokens=786
10:07:07,886 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:07,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.375. input_tokens=2102, output_tokens=583
10:07:08,616 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:08,619 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.422000000020489. input_tokens=3045, output_tokens=791
10:07:09,231 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:09,234 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 16.17200000002049. input_tokens=2122, output_tokens=627
10:07:09,808 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:09,811 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 27.780999999959022. input_tokens=2381, output_tokens=691
10:07:10,216 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:10,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.561999999918044. input_tokens=2259, output_tokens=656
10:07:10,857 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:11,94 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.672000000020489. input_tokens=2184, output_tokens=572
10:07:12,483 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:12,485 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 26.406999999890104. input_tokens=2169, output_tokens=689
10:07:12,664 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:12,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.983999999938533. input_tokens=2924, output_tokens=745
10:07:12,667 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:12,669 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.1399999998975545. input_tokens=2899, output_tokens=678
10:07:15,884 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:15,898 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.577999999979511. input_tokens=2247, output_tokens=742
10:07:19,60 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:19,61 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.516000000061467. input_tokens=2174, output_tokens=612
10:07:19,88 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:19,89 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.061999999918044. input_tokens=2129, output_tokens=678
10:07:20,230 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:20,232 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.484999999869615. input_tokens=2328, output_tokens=691
10:07:20,613 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:20,614 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.141000000061467. input_tokens=2060, output_tokens=560
10:07:24,417 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:24,419 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.9219999997876585. input_tokens=2218, output_tokens=642
10:07:25,211 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:25,213 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.922000000020489. input_tokens=2537, output_tokens=681
10:07:26,913 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:26,914 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.703999999910593. input_tokens=2281, output_tokens=584
10:07:27,326 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:27,328 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.937000000150874. input_tokens=2072, output_tokens=704
10:07:28,604 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:28,607 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.438000000081956. input_tokens=2426, output_tokens=693
10:07:29,178 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:29,180 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.171999999787658. input_tokens=2353, output_tokens=790
10:07:30,556 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:30,823 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.141000000061467. input_tokens=2096, output_tokens=642
10:07:33,503 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:33,506 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.984000000171363. input_tokens=2094, output_tokens=650
10:07:33,596 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:33,844 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.422000000020489. input_tokens=2103, output_tokens=609
10:07:34,506 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:34,507 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.5. input_tokens=2210, output_tokens=695
10:07:34,756 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:34,758 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.2030000002123415. input_tokens=2195, output_tokens=609
10:07:35,166 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:35,168 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.280999999959022. input_tokens=3259, output_tokens=678
10:07:36,553 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:36,855 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.0939999998081475. input_tokens=2306, output_tokens=736
10:07:40,400 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:40,402 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.266000000061467. input_tokens=3261, output_tokens=921
10:07:42,14 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:42,17 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.702999999979511. input_tokens=2959, output_tokens=709
10:07:42,192 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:42,196 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.75. input_tokens=2297, output_tokens=697
10:07:42,393 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:42,396 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 19.17200000002049. input_tokens=2929, output_tokens=912
10:07:43,587 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:43,589 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.140999999828637. input_tokens=2458, output_tokens=721
10:07:45,381 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:45,384 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.640000000130385. input_tokens=2632, output_tokens=632
10:07:45,617 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:45,619 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.7810000001918525. input_tokens=2673, output_tokens=693
10:07:46,300 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:46,302 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.5469999997876585. input_tokens=2190, output_tokens=709
10:07:48,345 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:48,347 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.125. input_tokens=2306, output_tokens=696
10:07:51,197 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:51,199 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.046000000089407. input_tokens=2355, output_tokens=785
10:07:51,737 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:51,739 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.109999999869615. input_tokens=2091, output_tokens=637
10:07:52,5 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:52,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.640000000130385. input_tokens=2679, output_tokens=897
10:07:52,990 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:52,992 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.844000000040978. input_tokens=2086, output_tokens=663
10:07:53,767 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:54,80 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.780999999959022. input_tokens=2710, output_tokens=797
10:07:56,280 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:56,282 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.016000000061467. input_tokens=2295, output_tokens=771
10:07:59,508 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:07:59,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.015999999828637. input_tokens=3276, output_tokens=814
10:08:00,800 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:00,801 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.1719999997876585. input_tokens=2379, output_tokens=700
10:08:03,591 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:03,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.311999999918044. input_tokens=2139, output_tokens=724
10:08:04,847 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:04,849 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.186999999918044. input_tokens=2588, output_tokens=745
10:08:05,626 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:05,628 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.9530000002123415. input_tokens=2446, output_tokens=775
10:08:05,676 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:05,957 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.8899999998975545. input_tokens=2782, output_tokens=696
10:08:08,225 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:08,227 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.765999999828637. input_tokens=3372, output_tokens=992
10:08:12,390 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:12,391 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.844000000040978. input_tokens=2401, output_tokens=690
10:08:13,566 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:13,568 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.937999999849126. input_tokens=2804, output_tokens=796
10:08:13,786 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:13,789 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 18.719000000040978. input_tokens=2571, output_tokens=839
10:08:14,266 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:14,267 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.030999999959022. input_tokens=2408, output_tokens=750
10:08:14,631 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:14,633 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.718000000109896. input_tokens=3343, output_tokens=864
10:08:15,465 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:15,467 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.202999999979511. input_tokens=3074, output_tokens=713
10:08:17,76 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:17,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.171000000089407. input_tokens=2579, output_tokens=776
10:08:19,720 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:19,722 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.422000000020489. input_tokens=3751, output_tokens=762
10:08:19,774 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:19,775 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.938000000081956. input_tokens=3419, output_tokens=705
10:08:21,860 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:21,861 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.219000000040978. input_tokens=3509, output_tokens=793
10:08:21,862 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:22,98 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:22,161 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.702999999979511. input_tokens=2243, output_tokens=735
10:08:22,631 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.811999999918044. input_tokens=2274, output_tokens=676
10:08:26,0 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:26,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.265000000130385. input_tokens=2063, output_tokens=575
10:08:28,282 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:28,285 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.531999999890104. input_tokens=4265, output_tokens=722
10:08:28,350 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:28,353 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.702999999979511. input_tokens=2124, output_tokens=639
10:08:29,214 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:29,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.608999999938533. input_tokens=2172, output_tokens=629
10:08:30,960 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:30,962 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.093999999808148. input_tokens=2686, output_tokens=758
10:08:31,633 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:31,635 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.75. input_tokens=2537, output_tokens=723
10:08:33,729 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:33,732 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.156999999890104. input_tokens=2899, output_tokens=814
10:08:37,240 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:37,241 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.391000000061467. input_tokens=2379, output_tokens=672
10:08:39,224 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:39,227 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.125. input_tokens=2331, output_tokens=656
10:08:39,994 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:39,996 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.890000000130385. input_tokens=2086, output_tokens=597
10:08:40,538 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:40,539 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.438000000081956. input_tokens=2619, output_tokens=763
10:08:44,561 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:44,565 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.344000000040978. input_tokens=4659, output_tokens=910
10:08:46,926 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:46,928 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.686999999918044. input_tokens=2144, output_tokens=628
10:08:47,307 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:47,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.562999999849126. input_tokens=3212, output_tokens=818
10:08:48,393 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:48,396 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.452999999979511. input_tokens=2449, output_tokens=647
10:08:49,5 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:49,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.797000000020489. input_tokens=2954, output_tokens=681
10:08:51,277 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:51,280 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 20.860000000102445. input_tokens=2767, output_tokens=757
10:08:52,946 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:52,948 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.421000000089407. input_tokens=2840, output_tokens=845
10:08:53,693 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:54,80 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.719000000040978. input_tokens=4215, output_tokens=925
10:08:56,40 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:56,121 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:56,235 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:56,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.906999999890104. input_tokens=2772, output_tokens=741
10:08:56,696 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.234000000171363. input_tokens=2169, output_tokens=714
10:08:57,132 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.936999999918044. input_tokens=3931, output_tokens=901
10:08:58,76 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:58,340 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.234000000171363. input_tokens=2217, output_tokens=688
10:08:59,461 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:59,463 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.952999999979511. input_tokens=2801, output_tokens=763
10:08:59,533 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:08:59,535 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.969000000040978. input_tokens=2928, output_tokens=774
10:09:00,691 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:00,693 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 26.109999999869615. input_tokens=2448, output_tokens=766
10:09:00,785 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:00,787 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.891000000061467. input_tokens=2423, output_tokens=707
10:09:04,136 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:04,139 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.265999999828637. input_tokens=2223, output_tokens=578
10:09:05,750 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:05,751 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.75. input_tokens=2721, output_tokens=767
10:09:06,18 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:06,23 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.672000000020489. input_tokens=3158, output_tokens=681
10:09:07,615 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:07,616 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.375. input_tokens=2120, output_tokens=655
10:09:08,162 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:08,165 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.75. input_tokens=2131, output_tokens=547
10:09:10,693 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:10,695 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.812999999849126. input_tokens=2611, output_tokens=675
10:09:13,860 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:14,150 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.375. input_tokens=2299, output_tokens=713
10:09:15,427 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:15,431 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.389999999897555. input_tokens=2392, output_tokens=683
10:09:17,201 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:17,203 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.5. input_tokens=2092, output_tokens=710
10:09:17,839 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:17,841 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.718999999808148. input_tokens=3054, output_tokens=739
10:09:19,978 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:19,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.422000000020489. input_tokens=2829, output_tokens=913
10:09:21,384 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:21,387 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.952999999979511. input_tokens=2064, output_tokens=586
10:09:22,530 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:22,532 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.328999999910593. input_tokens=2207, output_tokens=612
10:09:22,902 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:22,904 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.078999999910593. input_tokens=2768, output_tokens=625
10:09:23,92 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:23,93 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.25. input_tokens=2105, output_tokens=617
10:09:23,315 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:23,317 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.327999999979511. input_tokens=3113, output_tokens=715
10:09:23,705 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:23,708 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.0. input_tokens=4541, output_tokens=731
10:09:24,434 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:24,436 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 17.344000000040978. input_tokens=2479, output_tokens=734
10:09:28,675 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:28,678 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.0. input_tokens=2834, output_tokens=816
10:09:28,824 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:28,829 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.656000000191852. input_tokens=4424, output_tokens=896
10:09:31,293 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:31,296 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.061999999918044. input_tokens=2282, output_tokens=733
10:09:32,76 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:32,79 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.468000000109896. input_tokens=2928, output_tokens=720
10:09:32,311 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:32,313 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.547000000020489. input_tokens=2579, output_tokens=694
10:09:34,236 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:34,238 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.297000000020489. input_tokens=2440, output_tokens=734
10:09:36,34 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:36,37 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.469000000040978. input_tokens=2242, output_tokens=702
10:09:36,403 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:36,406 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.656999999890104. input_tokens=2427, output_tokens=766
10:09:37,711 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:37,713 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.186999999918044. input_tokens=3256, output_tokens=760
10:09:38,414 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:38,416 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.655999999959022. input_tokens=2298, output_tokens=634
10:09:38,974 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:38,976 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.780999999959022. input_tokens=2179, output_tokens=549
10:09:42,53 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:42,55 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.952999999979511. input_tokens=2503, output_tokens=858
10:09:43,866 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:43,868 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.4530000002123415. input_tokens=2088, output_tokens=527
10:09:45,14 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:45,22 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.297000000020489. input_tokens=2135, output_tokens=558
10:09:45,374 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:45,376 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.343000000109896. input_tokens=2903, output_tokens=724
10:09:47,124 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:47,126 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.265000000130385. input_tokens=2347, output_tokens=750
10:09:49,104 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:49,107 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.625. input_tokens=3635, output_tokens=918
10:09:49,421 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:49,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.405999999959022. input_tokens=2367, output_tokens=683
10:09:51,35 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:51,39 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.156999999890104. input_tokens=2139, output_tokens=607
10:09:52,419 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:52,421 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.655999999959022. input_tokens=3479, output_tokens=757
10:09:54,553 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:54,553 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.139999999897555. input_tokens=2572, output_tokens=837
10:09:55,615 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:55,941 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.547000000020489. input_tokens=2539, output_tokens=790
10:09:56,729 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:56,730 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.391000000061467. input_tokens=2327, output_tokens=720
10:09:58,44 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:58,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.077999999979511. input_tokens=2321, output_tokens=665
10:09:58,171 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:58,174 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.0. input_tokens=2534, output_tokens=719
10:09:59,475 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:09:59,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.938000000081956. input_tokens=2248, output_tokens=539
10:10:00,252 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:00,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.203000000212342. input_tokens=2414, output_tokens=705
10:10:07,788 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:07,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.875. input_tokens=2154, output_tokens=562
10:10:07,843 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:07,847 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.983999999938533. input_tokens=2691, output_tokens=877
10:10:08,407 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:08,409 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.656999999890104. input_tokens=2519, output_tokens=781
10:10:08,522 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:08,524 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.140999999828637. input_tokens=3705, output_tokens=732
10:10:10,855 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:10,857 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.063000000081956. input_tokens=2647, output_tokens=672
10:10:10,900 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:10,901 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.860000000102445. input_tokens=2220, output_tokens=672
10:10:13,696 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:13,758 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:13,946 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.452999999979511. input_tokens=2074, output_tokens=609
10:10:14,484 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.062999999849126. input_tokens=4347, output_tokens=912
10:10:14,520 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:14,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.265999999828637. input_tokens=3855, output_tokens=938
10:10:14,936 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:14,939 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.094000000040978. input_tokens=2385, output_tokens=750
10:10:15,898 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:15,901 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.828999999910593. input_tokens=2533, output_tokens=704
10:10:16,491 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:16,494 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.640000000130385. input_tokens=2503, output_tokens=642
10:10:19,607 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:19,608 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.327999999979511. input_tokens=3454, output_tokens=770
10:10:22,78 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:22,80 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.859000000171363. input_tokens=2143, output_tokens=683
10:10:23,870 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:23,872 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.765000000130385. input_tokens=2086, output_tokens=585
10:10:24,28 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:24,31 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.344000000040978. input_tokens=3807, output_tokens=805
10:10:26,826 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:26,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.468000000109896. input_tokens=2230, output_tokens=672
10:10:26,892 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:26,894 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.483999999938533. input_tokens=2839, output_tokens=871
10:10:29,589 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:29,592 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.311999999918044. input_tokens=2991, output_tokens=792
10:10:30,718 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:30,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.983999999938533. input_tokens=2628, output_tokens=774
10:10:31,331 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:31,333 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.5. input_tokens=3545, output_tokens=715
10:10:32,360 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:32,362 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.547000000020489. input_tokens=2443, output_tokens=720
10:10:32,968 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:32,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.780999999959022. input_tokens=2107, output_tokens=614
10:10:37,942 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:37,944 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.609999999869615. input_tokens=3071, output_tokens=868
10:10:38,436 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:38,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.469000000040978. input_tokens=2830, output_tokens=912
10:10:40,62 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:40,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.375. input_tokens=2776, output_tokens=758
10:10:40,414 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:40,594 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:40,595 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.655999999959022. input_tokens=2927, output_tokens=957
10:10:40,784 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:40,983 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.608999999938533. input_tokens=2189, output_tokens=696
10:10:41,436 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.906999999890104. input_tokens=3520, output_tokens=811
10:10:41,884 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:41,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.030999999959022. input_tokens=2395, output_tokens=635
10:10:42,43 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:42,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.125. input_tokens=2280, output_tokens=631
10:10:43,891 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:43,893 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.452999999979511. input_tokens=2709, output_tokens=670
10:10:45,599 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:45,601 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.608999999938533. input_tokens=3717, output_tokens=691
10:10:48,470 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:48,472 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.733999999938533. input_tokens=2211, output_tokens=660
10:10:48,869 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:48,871 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.2030000002123415. input_tokens=2224, output_tokens=558
10:10:50,458 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:50,460 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.671000000089407. input_tokens=2273, output_tokens=558
10:10:52,175 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:52,436 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.2189999998081475. input_tokens=2153, output_tokens=651
10:10:53,419 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:53,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.327999999979511. input_tokens=3274, output_tokens=732
10:10:56,457 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:56,459 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.187000000150874. input_tokens=2802, output_tokens=919
10:10:59,83 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:59,88 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.171000000089407. input_tokens=2554, output_tokens=821
10:10:59,881 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:10:59,883 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.765000000130385. input_tokens=2277, output_tokens=643
10:11:00,462 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:00,464 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.155999999959022. input_tokens=2383, output_tokens=734
10:11:01,122 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:01,126 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.031000000191852. input_tokens=2762, output_tokens=864
10:11:02,663 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:02,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.4850000001024455. input_tokens=2372, output_tokens=711
10:11:03,296 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:03,298 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.233999999938533. input_tokens=3866, output_tokens=833
10:11:04,500 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:04,503 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.984000000171363. input_tokens=2668, output_tokens=717
10:11:05,1 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:05,2 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.0780000002123415. input_tokens=2044, output_tokens=518
10:11:06,752 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:06,755 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.062000000150874. input_tokens=2796, output_tokens=807
10:11:07,997 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:07,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.015000000130385. input_tokens=2130, output_tokens=640
10:11:10,585 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:10,587 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.327999999979511. input_tokens=2211, output_tokens=576
10:11:12,144 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:12,146 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.827999999979511. input_tokens=2508, output_tokens=882
10:11:12,295 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:12,571 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.764999999897555. input_tokens=2574, output_tokens=693
10:11:12,994 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:12,996 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.0. input_tokens=2084, output_tokens=557
10:11:16,593 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:16,603 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.952999999979511. input_tokens=2213, output_tokens=646
10:11:17,389 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:17,392 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.0. input_tokens=4459, output_tokens=734
10:11:18,470 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:18,472 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.733999999938533. input_tokens=2827, output_tokens=810
10:11:20,572 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:20,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.75. input_tokens=2056, output_tokens=564
10:11:22,667 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:22,670 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.686999999918044. input_tokens=2790, output_tokens=852
10:11:22,968 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:22,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.922000000020489. input_tokens=2564, output_tokens=679
10:11:23,435 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:23,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.391000000061467. input_tokens=3120, output_tokens=759
10:11:23,533 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:23,535 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.781999999890104. input_tokens=2839, output_tokens=711
10:11:28,282 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:28,284 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.438000000081956. input_tokens=2990, output_tokens=768
10:11:29,420 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:29,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.9689999998081475. input_tokens=2287, output_tokens=608
10:11:29,675 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:29,677 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.264999999897555. input_tokens=2501, output_tokens=815
10:11:30,89 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:30,91 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.811999999918044. input_tokens=4462, output_tokens=908
10:11:33,451 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:33,454 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.202999999979511. input_tokens=4126, output_tokens=896
10:11:34,333 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:34,339 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.686999999918044. input_tokens=3296, output_tokens=830
10:11:34,779 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:34,781 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.688000000081956. input_tokens=3230, output_tokens=669
10:11:36,558 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:36,560 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.141000000061467. input_tokens=2512, output_tokens=710
10:11:38,974 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:38,975 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.515999999828637. input_tokens=3465, output_tokens=760
10:11:40,736 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:40,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.109999999869615. input_tokens=2670, output_tokens=751
10:11:44,12 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:44,15 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.547000000020489. input_tokens=2109, output_tokens=638
10:11:44,793 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:45,51 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.375. input_tokens=2116, output_tokens=635
10:11:45,251 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:45,355 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:45,357 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.391000000061467. input_tokens=2210, output_tokens=596
10:11:45,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.812000000150874. input_tokens=2763, output_tokens=833
10:11:46,813 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:46,816 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.25. input_tokens=2054, output_tokens=534
10:11:51,188 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:51,190 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.094000000040978. input_tokens=4112, output_tokens=762
10:11:51,911 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:51,913 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.375. input_tokens=4116, output_tokens=793
10:11:55,320 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:55,323 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.921000000089407. input_tokens=2676, output_tokens=663
10:11:55,325 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:55,328 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.562000000150874. input_tokens=4052, output_tokens=768
10:11:57,55 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:57,57 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.094000000040978. input_tokens=2878, output_tokens=686
10:11:57,863 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:11:57,864 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.359999999869615. input_tokens=2612, output_tokens=694
10:12:00,180 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:00,182 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.530999999959022. input_tokens=4044, output_tokens=770
10:12:00,749 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:00,751 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.25. input_tokens=2892, output_tokens=757
10:12:02,683 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:02,686 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.452999999979511. input_tokens=2277, output_tokens=680
10:12:02,910 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:02,911 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.047000000020489. input_tokens=3575, output_tokens=875
10:12:03,225 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:03,228 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.375. input_tokens=2214, output_tokens=555
10:12:04,10 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:04,11 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.202999999979511. input_tokens=2191, output_tokens=606
10:12:05,245 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:05,248 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.234000000171363. input_tokens=2452, output_tokens=706
10:12:08,414 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:08,416 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.0. input_tokens=2607, output_tokens=848
10:12:08,509 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:08,511 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.922000000020489. input_tokens=2106, output_tokens=558
10:12:09,858 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:09,859 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.172000000020489. input_tokens=2334, output_tokens=666
10:12:10,726 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:10,739 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.016000000061467. input_tokens=2134, output_tokens=535
10:12:12,266 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:12,268 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.937999999849126. input_tokens=2663, output_tokens=662
10:12:12,659 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:12,662 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.469000000040978. input_tokens=2347, output_tokens=782
10:12:15,570 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:15,571 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.625. input_tokens=2121, output_tokens=569
10:12:17,67 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:17,69 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.641000000061467. input_tokens=2297, output_tokens=606
10:12:18,68 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:18,69 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.0. input_tokens=4014, output_tokens=822
10:12:20,838 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:20,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.047000000020489. input_tokens=2670, output_tokens=701
10:12:21,893 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:21,895 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.108999999938533. input_tokens=2827, output_tokens=831
10:12:22,692 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:22,696 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.109999999869615. input_tokens=2205, output_tokens=709
10:12:22,834 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:22,838 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.780999999959022. input_tokens=2596, output_tokens=723
10:12:23,120 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:23,122 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.375. input_tokens=2091, output_tokens=638
10:12:23,904 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:23,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.844000000040978. input_tokens=2297, output_tokens=647
10:12:26,489 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:26,502 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.0780000002123415. input_tokens=2732, output_tokens=762
10:12:27,52 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:27,55 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.155999999959022. input_tokens=2110, output_tokens=610
10:12:29,324 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:29,327 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.484000000171363. input_tokens=2518, output_tokens=803
10:12:29,904 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:29,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.2350000001024455. input_tokens=2404, output_tokens=856
10:12:31,145 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:31,146 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.187999999849126. input_tokens=2295, output_tokens=679
10:12:32,418 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:32,419 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.405999999959022. input_tokens=2651, output_tokens=732
10:12:34,316 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:34,317 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.094000000040978. input_tokens=2770, output_tokens=707
10:12:37,311 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:37,313 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.984999999869615. input_tokens=2284, output_tokens=647
10:12:38,535 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:38,536 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.281999999890104. input_tokens=2276, output_tokens=700
10:12:41,62 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:41,63 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.516000000061467. input_tokens=4704, output_tokens=920
10:12:42,456 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:42,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.296000000089407. input_tokens=3168, output_tokens=837
10:12:43,727 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:43,730 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.577999999979511. input_tokens=5223, output_tokens=923
10:12:43,933 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:43,935 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.780999999959022. input_tokens=4364, output_tokens=691
10:12:50,292 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:50,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.983999999938533. input_tokens=4495, output_tokens=778
10:12:51,820 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:51,823 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.452999999979511. input_tokens=5082, output_tokens=783
10:12:54,154 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:54,157 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.266000000061467. input_tokens=4902, output_tokens=763
10:12:55,329 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:12:55,331 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.984000000171363. input_tokens=5273, output_tokens=812
10:13:00,465 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:00,468 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.733999999938533. input_tokens=5359, output_tokens=803
10:13:01,862 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:01,864 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.219000000040978. input_tokens=5739, output_tokens=999
10:13:06,43 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:06,46 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.733999999938533. input_tokens=5679, output_tokens=990
10:13:06,797 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:06,800 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.530999999959022. input_tokens=4833, output_tokens=967
10:13:07,589 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:07,591 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.811999999918044. input_tokens=5275, output_tokens=852
10:13:11,564 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:11,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.155999999959022. input_tokens=7844, output_tokens=868
10:13:12,767 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:12,770 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.530999999959022. input_tokens=5817, output_tokens=756
10:13:20,740 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:20,743 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.469000000040978. input_tokens=6857, output_tokens=1116
10:13:24,81 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:24,85 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.546000000089407. input_tokens=9862, output_tokens=858
10:13:27,365 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:27,366 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.734999999869615. input_tokens=6923, output_tokens=1008
10:13:31,282 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:31,285 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.531999999890104. input_tokens=8106, output_tokens=1102
10:13:32,577 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:32,579 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.531000000191852. input_tokens=8213, output_tokens=998
10:13:40,64 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:40,67 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.780999999959022. input_tokens=9873, output_tokens=978
10:13:46,783 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:46,787 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.25. input_tokens=9907, output_tokens=1010
10:13:54,152 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:54,161 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.766000000061467. input_tokens=2929, output_tokens=743
10:13:54,363 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:54,366 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.938000000081956. input_tokens=3344, output_tokens=768
10:13:54,657 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:54,660 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.203999999910593. input_tokens=2982, output_tokens=850
10:13:54,703 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:54,827 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:54,830 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.390000000130385. input_tokens=2442, output_tokens=773
10:13:55,157 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:55,160 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.641000000061467. input_tokens=2488, output_tokens=671
10:13:55,367 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:55,369 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.968000000109896. input_tokens=2288, output_tokens=774
10:13:55,416 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:55,519 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:55,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.9689999998081475. input_tokens=2678, output_tokens=756
10:13:55,837 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:56,125 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.234000000171363. input_tokens=2818, output_tokens=717
10:13:56,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.436999999918044. input_tokens=3229, output_tokens=771
10:13:56,775 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:56,778 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.344000000040978. input_tokens=2548, output_tokens=829
10:13:57,184 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.125. input_tokens=3200, output_tokens=846
10:13:58,173 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:58,175 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.733999999938533. input_tokens=3747, output_tokens=889
10:13:59,414 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:13:59,761 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.8899999998975545. input_tokens=3381, output_tokens=829
10:14:00,437 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:00,440 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.280999999959022. input_tokens=2339, output_tokens=664
10:14:01,869 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:01,872 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.25. input_tokens=2617, output_tokens=823
10:14:02,506 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:02,509 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 15.078000000212342. input_tokens=3095, output_tokens=757
10:14:02,863 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:02,865 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.125. input_tokens=2656, output_tokens=675
10:14:05,429 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:05,430 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.3439999998081475. input_tokens=2037, output_tokens=509
10:14:05,953 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:05,955 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.7810000001918525. input_tokens=2507, output_tokens=736
10:14:08,407 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:08,614 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:08,695 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.125. input_tokens=2337, output_tokens=704
10:14:08,953 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.577999999979511. input_tokens=3071, output_tokens=844
10:14:10,344 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:10,346 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.140999999828637. input_tokens=2080, output_tokens=563
10:14:10,892 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:10,895 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.797000000020489. input_tokens=3070, output_tokens=755
10:14:13,841 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:13,844 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.265999999828637. input_tokens=2677, output_tokens=730
10:14:14,139 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:14,141 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.327999999979511. input_tokens=2122, output_tokens=581
10:14:17,824 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:17,826 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.921000000089407. input_tokens=2305, output_tokens=697
10:14:18,441 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:18,442 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.062999999849126. input_tokens=2642, output_tokens=733
10:14:19,580 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:19,582 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.734000000171363. input_tokens=2963, output_tokens=803
10:14:22,310 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:22,317 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.187999999849126. input_tokens=3138, output_tokens=818
10:14:23,83 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:23,86 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.765000000130385. input_tokens=3725, output_tokens=702
10:14:24,181 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:24,183 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.062999999849126. input_tokens=3656, output_tokens=896
10:14:25,678 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:25,681 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.280999999959022. input_tokens=2355, output_tokens=628
10:14:25,826 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:26,151 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.202999999979511. input_tokens=3049, output_tokens=819
10:14:28,593 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:28,595 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.875. input_tokens=3437, output_tokens=803
10:14:31,272 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:31,276 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.563000000081956. input_tokens=3199, output_tokens=789
10:14:33,485 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:33,488 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.938000000081956. input_tokens=3257, output_tokens=757
10:14:33,861 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:33,864 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.563000000081956. input_tokens=2786, output_tokens=840
10:14:34,501 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:34,504 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.109000000171363. input_tokens=3189, output_tokens=843
10:14:36,18 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:36,20 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.422000000020489. input_tokens=2371, output_tokens=635
10:14:37,460 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:37,757 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.547000000020489. input_tokens=2972, output_tokens=724
10:14:37,801 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:38,99 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.6719999997876585. input_tokens=2760, output_tokens=769
10:14:39,501 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:39,503 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.5310000001918525. input_tokens=3652, output_tokens=805
10:14:41,685 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:41,687 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.187999999849126. input_tokens=2364, output_tokens=694
10:14:42,659 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:42,660 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.641000000061467. input_tokens=2181, output_tokens=725
10:14:44,999 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:45,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.609000000171363. input_tokens=4158, output_tokens=838
10:14:46,689 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:46,690 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.405999999959022. input_tokens=2243, output_tokens=770
10:14:48,70 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:48,73 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.625. input_tokens=3300, output_tokens=780
10:14:49,767 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:49,769 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.594000000040978. input_tokens=3325, output_tokens=852
10:14:52,380 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:52,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.8280000002123415. input_tokens=2149, output_tokens=629
10:14:54,24 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:54,26 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.922000000020489. input_tokens=3856, output_tokens=878
10:14:54,203 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:54,204 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.312000000150874. input_tokens=3835, output_tokens=818
10:14:57,740 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:57,742 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.156999999890104. input_tokens=3282, output_tokens=771
10:14:58,27 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:58,30 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.266000000061467. input_tokens=2951, output_tokens=774
10:14:59,333 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:59,335 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.077999999979511. input_tokens=2175, output_tokens=650
10:14:59,394 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:14:59,397 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.312999999849126. input_tokens=4331, output_tokens=877
10:15:00,863 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:00,865 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.938000000081956. input_tokens=2201, output_tokens=621
10:15:02,932 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:03,130 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:03,131 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.390000000130385. input_tokens=2042, output_tokens=504
10:15:03,241 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.344000000040978. input_tokens=3424, output_tokens=756
10:15:03,817 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:03,818 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.905999999959022. input_tokens=2181, output_tokens=570
10:15:09,216 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:09,220 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.922000000020489. input_tokens=2461, output_tokens=768
10:15:09,707 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:09,708 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.077999999979511. input_tokens=3770, output_tokens=728
10:15:10,797 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:10,800 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.875. input_tokens=2943, output_tokens=781
10:15:11,257 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:11,259 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.390999999828637. input_tokens=2181, output_tokens=628
10:15:13,352 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:13,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.875. input_tokens=2895, output_tokens=791
10:15:15,271 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:15,273 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.172000000020489. input_tokens=3678, output_tokens=915
10:15:15,544 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:15,548 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.2969999997876585. input_tokens=2662, output_tokens=742
10:15:16,958 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:16,960 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.812000000150874. input_tokens=3950, output_tokens=755
10:15:17,917 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:17,921 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.75. input_tokens=2277, output_tokens=741
10:15:20,603 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:20,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.75. input_tokens=4290, output_tokens=754
10:15:20,888 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:20,892 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.530999999959022. input_tokens=2579, output_tokens=815
10:15:24,628 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:24,630 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.984000000171363. input_tokens=2800, output_tokens=634
10:15:25,130 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:25,131 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.297000000020489. input_tokens=3592, output_tokens=723
10:15:27,552 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:27,555 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.7969999997876585. input_tokens=2394, output_tokens=647
10:15:28,799 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:29,81 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.108999999938533. input_tokens=2877, output_tokens=708
10:15:31,493 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:31,495 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.375. input_tokens=2707, output_tokens=786
10:15:32,663 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:32,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.625. input_tokens=3035, output_tokens=803
10:15:34,816 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:34,818 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.234999999869615. input_tokens=2372, output_tokens=876
10:15:36,91 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:36,93 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.297000000020489. input_tokens=4155, output_tokens=996
10:15:38,675 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:38,678 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.8439999998081475. input_tokens=4373, output_tokens=826
10:15:39,236 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:39,238 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.563000000081956. input_tokens=4286, output_tokens=1057
10:15:40,386 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:40,388 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.577999999979511. input_tokens=2680, output_tokens=720
10:15:41,511 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:41,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.358999999938533. input_tokens=4595, output_tokens=764
10:15:43,793 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:43,797 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.7189999998081475. input_tokens=4162, output_tokens=796
10:15:45,211 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:45,212 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.030999999959022. input_tokens=2384, output_tokens=624
10:15:46,651 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:46,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.9850000001024455. input_tokens=4241, output_tokens=1024
10:15:51,990 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:51,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.266000000061467. input_tokens=4552, output_tokens=891
10:15:52,918 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:52,920 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.233999999938533. input_tokens=3970, output_tokens=825
10:15:54,17 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:54,20 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.937999999849126. input_tokens=2851, output_tokens=717
10:15:54,716 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:54,719 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.155999999959022. input_tokens=2934, output_tokens=810
10:15:55,331 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:55,335 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.75. input_tokens=2414, output_tokens=675
10:15:58,197 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:15:58,199 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.171000000089407. input_tokens=4215, output_tokens=818
10:16:00,330 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:00,332 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.327999999979511. input_tokens=2887, output_tokens=705
10:16:00,930 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:00,934 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.922000000020489. input_tokens=2457, output_tokens=774
10:16:02,28 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:02,29 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.313000000081956. input_tokens=3176, output_tokens=796
10:16:02,628 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:02,630 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.3280000002123415. input_tokens=2422, output_tokens=736
10:16:07,103 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:07,106 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.422000000020489. input_tokens=3940, output_tokens=717
10:16:08,194 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:08,197 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.359000000171363. input_tokens=3460, output_tokens=779
10:16:09,227 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:09,573 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.469000000040978. input_tokens=4547, output_tokens=849
10:16:11,821 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:11,822 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.187000000150874. input_tokens=2931, output_tokens=757
10:16:12,357 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:12,361 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.234999999869615. input_tokens=3769, output_tokens=680
10:16:14,651 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:14,654 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.906999999890104. input_tokens=4006, output_tokens=850
10:16:15,648 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:15,656 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.5. input_tokens=4859, output_tokens=836
10:16:17,229 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:17,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.047000000020489. input_tokens=3400, output_tokens=746
10:16:20,869 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:20,882 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.140000000130385. input_tokens=2250, output_tokens=671
10:16:23,689 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:23,691 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.437999999849126. input_tokens=3974, output_tokens=718
10:16:23,765 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:23,768 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.983999999938533. input_tokens=3571, output_tokens=935
10:16:23,931 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:23,933 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.437999999849126. input_tokens=2957, output_tokens=671
10:16:25,334 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:25,336 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.984000000171363. input_tokens=4616, output_tokens=826
10:16:29,135 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:29,137 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.265999999828637. input_tokens=2712, output_tokens=849
10:16:31,505 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:31,507 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.656000000191852. input_tokens=4736, output_tokens=842
10:16:31,884 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:31,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.219000000040978. input_tokens=2398, output_tokens=681
10:16:32,147 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:32,151 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.516000000061467. input_tokens=2347, output_tokens=693
10:16:33,27 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:33,30 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.4850000001024455. input_tokens=2184, output_tokens=656
10:16:35,776 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:35,777 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.266000000061467. input_tokens=4226, output_tokens=838
10:16:38,428 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:38,430 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.9219999997876585. input_tokens=3027, output_tokens=751
10:16:40,286 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:40,289 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.516000000061467. input_tokens=4028, output_tokens=730
10:16:41,698 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:41,700 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.546000000089407. input_tokens=2515, output_tokens=949
10:16:44,92 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:44,93 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.358999999938533. input_tokens=2358, output_tokens=733
10:16:44,561 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:44,564 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.062999999849126. input_tokens=3075, output_tokens=722
10:16:46,339 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:46,342 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.047000000020489. input_tokens=2256, output_tokens=627
10:16:46,531 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:46,533 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.156999999890104. input_tokens=2333, output_tokens=728
10:16:47,255 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:47,258 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.125. input_tokens=4508, output_tokens=975
10:16:49,621 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:49,623 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.843000000109896. input_tokens=4357, output_tokens=774
10:16:50,163 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:50,165 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.608999999938533. input_tokens=2154, output_tokens=538
10:16:52,341 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:52,343 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.280999999959022. input_tokens=3649, output_tokens=794
10:16:52,608 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:52,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.344000000040978. input_tokens=2100, output_tokens=557
10:16:58,119 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:58,121 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.375. input_tokens=2656, output_tokens=676
10:16:58,490 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:58,493 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.577999999979511. input_tokens=2993, output_tokens=813
10:16:59,369 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:16:59,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.203000000212342. input_tokens=2831, output_tokens=783
10:17:00,727 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:00,729 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.906999999890104. input_tokens=3036, output_tokens=783
10:17:03,340 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:03,343 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.280999999959022. input_tokens=5304, output_tokens=846
10:17:04,595 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:04,597 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.4689999998081475. input_tokens=2354, output_tokens=615
10:17:05,691 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:05,693 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.641000000061467. input_tokens=4965, output_tokens=981
10:17:08,385 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:08,388 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.0. input_tokens=2344, output_tokens=655
10:17:09,120 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:09,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.062000000150874. input_tokens=2916, output_tokens=767
10:17:11,636 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:11,639 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.297000000020489. input_tokens=2479, output_tokens=754
10:17:11,913 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:12,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.311999999918044. input_tokens=2776, output_tokens=995
10:17:16,269 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:16,272 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.030999999959022. input_tokens=4840, output_tokens=994
10:17:17,323 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:17,325 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.327999999979511. input_tokens=4110, output_tokens=878
10:17:19,143 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:19,145 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.280999999959022. input_tokens=4868, output_tokens=748
10:17:19,505 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:19,507 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.422000000020489. input_tokens=2380, output_tokens=573
10:17:25,68 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:25,70 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.187999999849126. input_tokens=3868, output_tokens=706
10:17:25,443 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:25,445 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.891000000061467. input_tokens=5874, output_tokens=1061
10:17:25,995 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:25,997 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.172000000020489. input_tokens=4764, output_tokens=1001
10:17:27,656 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:27,659 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.078999999910593. input_tokens=2593, output_tokens=674
10:17:27,906 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:28,222 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.531999999890104. input_tokens=3108, output_tokens=784
10:17:32,77 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:32,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.671000000089407. input_tokens=2382, output_tokens=624
10:17:33,952 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:33,955 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.296000000089407. input_tokens=2379, output_tokens=712
10:17:34,789 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:34,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.202999999979511. input_tokens=7555, output_tokens=917
10:17:37,678 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:37,680 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.702999999979511. input_tokens=2553, output_tokens=744
10:17:38,76 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:38,78 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.0. input_tokens=2272, output_tokens=596
10:17:42,613 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:42,616 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.281999999890104. input_tokens=2776, output_tokens=727
10:17:42,712 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:42,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.030999999959022. input_tokens=2064, output_tokens=602
10:17:42,742 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:42,745 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.843000000109896. input_tokens=5555, output_tokens=866
10:17:44,356 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:44,358 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.531999999890104. input_tokens=2556, output_tokens=715
10:17:44,606 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:44,608 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.202999999979511. input_tokens=3074, output_tokens=715
10:17:45,689 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:45,690 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.922000000020489. input_tokens=4204, output_tokens=690
10:17:49,955 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:49,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.187000000150874. input_tokens=5911, output_tokens=778
10:17:50,6 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:50,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.390000000130385. input_tokens=2209, output_tokens=724
10:17:52,242 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:52,244 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.9060000001918525. input_tokens=2436, output_tokens=724
10:17:53,762 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:53,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.969000000040978. input_tokens=3477, output_tokens=768
10:17:55,555 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:55,556 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.609999999869615. input_tokens=2189, output_tokens=599
10:17:56,185 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:56,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.391000000061467. input_tokens=3889, output_tokens=789
10:17:57,247 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:17:57,249 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.109000000171363. input_tokens=2818, output_tokens=753
10:18:00,434 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:00,435 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.922000000020489. input_tokens=3066, output_tokens=802
10:18:03,317 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:03,320 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.812999999849126. input_tokens=2777, output_tokens=854
10:18:04,977 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:04,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.734999999869615. input_tokens=2882, output_tokens=787
10:18:05,528 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:05,531 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.391000000061467. input_tokens=3674, output_tokens=761
10:18:07,20 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:07,23 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.062999999849126. input_tokens=2746, output_tokens=754
10:18:08,406 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:08,408 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.969000000040978. input_tokens=3566, output_tokens=891
10:18:08,547 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:08,549 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.2969999997876585. input_tokens=5230, output_tokens=783
10:18:12,425 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:12,427 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.3899999998975545. input_tokens=2219, output_tokens=593
10:18:13,62 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:13,64 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.547000000020489. input_tokens=2958, output_tokens=788
10:18:13,771 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:13,773 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.233999999938533. input_tokens=2563, output_tokens=749
10:18:15,219 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:15,221 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.140999999828637. input_tokens=3413, output_tokens=707
10:18:19,248 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:19,249 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.468000000109896. input_tokens=2076, output_tokens=630
10:18:19,561 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:19,581 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.125. input_tokens=5935, output_tokens=943
10:18:20,575 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:20,577 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.156000000191852. input_tokens=2445, output_tokens=817
10:18:20,996 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:20,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.968000000109896. input_tokens=2071, output_tokens=543
10:18:21,46 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:21,322 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.155999999959022. input_tokens=2276, output_tokens=678
10:18:25,443 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:25,446 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.297000000020489. input_tokens=5518, output_tokens=731
10:18:26,320 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:26,323 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.75. input_tokens=2412, output_tokens=761
10:18:29,291 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:29,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.296999999787658. input_tokens=2180, output_tokens=620
10:18:29,765 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:29,767 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.077999999979511. input_tokens=2198, output_tokens=703
10:18:30,177 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:30,180 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.6399999998975545. input_tokens=2440, output_tokens=799
10:18:32,963 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:32,965 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.655999999959022. input_tokens=2149, output_tokens=625
10:18:33,265 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:33,268 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.077999999979511. input_tokens=3716, output_tokens=887
10:18:34,999 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:35,2 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.593000000109896. input_tokens=2693, output_tokens=780
10:18:35,726 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:35,728 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.563000000081956. input_tokens=4280, output_tokens=824
10:18:37,380 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:37,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.765000000130385. input_tokens=2088, output_tokens=754
10:18:40,242 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:40,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.140000000130385. input_tokens=2118, output_tokens=622
10:18:40,968 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:40,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.218999999808148. input_tokens=2119, output_tokens=667
10:18:41,52 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:41,54 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.5469999997876585. input_tokens=2109, output_tokens=578
10:18:41,735 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:41,737 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.063000000081956. input_tokens=2078, output_tokens=522
10:18:42,774 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:42,778 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.110000000102445. input_tokens=2961, output_tokens=1052
10:18:45,579 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:45,581 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.765000000130385. input_tokens=2597, output_tokens=680
10:18:47,460 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:47,462 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.061999999918044. input_tokens=2519, output_tokens=746
10:18:47,674 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:47,675 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.4219999997876585. input_tokens=2486, output_tokens=743
10:18:48,163 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:48,167 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.202999999979511. input_tokens=2303, output_tokens=731
10:18:51,381 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:51,383 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.4530000002123415. input_tokens=2678, output_tokens=747
10:18:53,81 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:53,83 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.609000000171363. input_tokens=2299, output_tokens=685
10:18:53,209 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:53,554 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.125. input_tokens=2631, output_tokens=851
10:18:55,612 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:55,615 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.031999999890104. input_tokens=2542, output_tokens=796
10:18:57,62 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:57,63 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.672000000020489. input_tokens=2092, output_tokens=699
10:18:59,717 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:18:59,719 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.061999999918044. input_tokens=2458, output_tokens=652
10:19:01,858 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:01,861 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.202999999979511. input_tokens=4884, output_tokens=932
10:19:02,121 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:02,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.8280000002123415. input_tokens=2769, output_tokens=709
10:19:02,531 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:02,534 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.891000000061467. input_tokens=3669, output_tokens=889
10:19:02,869 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:02,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.0780000002123415. input_tokens=2973, output_tokens=740
10:19:03,241 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:03,243 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.344000000040978. input_tokens=2083, output_tokens=511
10:19:05,579 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:05,581 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.765000000130385. input_tokens=4497, output_tokens=749
10:19:07,205 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:07,207 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.546000000089407. input_tokens=2309, output_tokens=682
10:19:09,280 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:09,282 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.422000000020489. input_tokens=3549, output_tokens=840
10:19:10,31 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:10,32 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.8600000001024455. input_tokens=2309, output_tokens=731
10:19:11,647 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:11,649 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.25. input_tokens=2101, output_tokens=669
10:19:11,887 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:11,889 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.405999999959022. input_tokens=2254, output_tokens=640
10:19:12,926 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:12,928 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.7189999998081475. input_tokens=2125, output_tokens=617
10:19:14,814 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:14,816 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.812999999849126. input_tokens=2693, output_tokens=640
10:19:16,170 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:16,172 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.1399999998975545. input_tokens=2475, output_tokens=656
10:19:18,827 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:18,829 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.702999999979511. input_tokens=2291, output_tokens=691
10:19:19,870 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:19,872 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.0780000002123415. input_tokens=2253, output_tokens=726
10:19:20,642 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:20,644 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.827999999979511. input_tokens=2265, output_tokens=687
10:19:22,556 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:22,557 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.75. input_tokens=2143, output_tokens=649
10:19:24,589 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:24,591 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.765999999828637. input_tokens=2083, output_tokens=604
10:19:24,938 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:24,940 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.516000000061467. input_tokens=4777, output_tokens=907
10:19:27,67 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:27,69 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.344000000040978. input_tokens=2128, output_tokens=614
10:19:28,142 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:28,143 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.625. input_tokens=4188, output_tokens=760
10:19:31,502 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:31,504 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.859000000171363. input_tokens=3752, output_tokens=868
10:19:31,979 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:31,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.391000000061467. input_tokens=3884, output_tokens=705
10:19:32,488 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:32,490 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.327999999979511. input_tokens=3074, output_tokens=801
10:19:36,754 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:36,761 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.0. input_tokens=3350, output_tokens=783
10:19:37,243 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:37,245 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.109000000171363. input_tokens=4344, output_tokens=967
10:19:39,668 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:39,669 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.686999999918044. input_tokens=2345, output_tokens=664
10:19:39,959 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:39,962 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.734000000171363. input_tokens=4295, output_tokens=885
10:19:41,521 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:41,523 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.75. input_tokens=2201, output_tokens=590
10:19:45,251 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:45,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.015000000130385. input_tokens=5298, output_tokens=1061
10:19:45,581 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:45,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.702999999979511. input_tokens=4044, output_tokens=693
10:19:48,760 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:48,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.702999999979511. input_tokens=2732, output_tokens=821
10:19:49,948 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:49,950 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.281000000191852. input_tokens=2427, output_tokens=873
10:19:51,454 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:51,456 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.859000000171363. input_tokens=2568, output_tokens=656
10:19:54,846 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:54,847 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.468999999808148. input_tokens=5909, output_tokens=818
10:19:55,431 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:55,433 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.030999999959022. input_tokens=3955, output_tokens=763
10:19:57,289 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:57,291 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.530999999959022. input_tokens=3293, output_tokens=747
10:19:58,654 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:58,656 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.8600000001024455. input_tokens=5073, output_tokens=756
10:19:59,441 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:19:59,835 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.984999999869615. input_tokens=3412, output_tokens=985
10:20:01,74 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:01,77 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.234000000171363. input_tokens=3942, output_tokens=765
10:20:06,800 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:06,802 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.030999999959022. input_tokens=3351, output_tokens=1037
10:20:09,974 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:09,976 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.718999999808148. input_tokens=6022, output_tokens=808
10:20:10,734 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:10,737 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.609999999869615. input_tokens=6665, output_tokens=817
10:20:12,770 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:12,772 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.875. input_tokens=5703, output_tokens=771
10:20:16,245 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:16,247 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.718000000109896. input_tokens=8158, output_tokens=867
10:20:20,610 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:20,613 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.906999999890104. input_tokens=7672, output_tokens=846
10:20:26,29 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:26,30 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.203999999910593. input_tokens=7084, output_tokens=834
10:20:27,670 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:27,672 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.139999999897555. input_tokens=6747, output_tokens=944
10:20:29,420 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:29,423 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.7189999998081475. input_tokens=7173, output_tokens=958
10:20:34,602 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:34,605 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.969000000040978. input_tokens=6649, output_tokens=1017
10:20:36,867 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:36,870 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.562000000150874. input_tokens=8127, output_tokens=868
10:20:40,352 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:40,356 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.359999999869615. input_tokens=7486, output_tokens=743
10:20:41,168 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:41,170 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 6.061999999918044. input_tokens=7675, output_tokens=751
10:20:48,200 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:48,202 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.202999999979511. input_tokens=8207, output_tokens=882
10:20:56,355 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:56,356 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.234999999869615. input_tokens=9725, output_tokens=752
10:20:57,168 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:20:57,170 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.625. input_tokens=8441, output_tokens=920
10:21:00,270 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:00,271 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.219000000040978. input_tokens=8482, output_tokens=872
10:21:03,346 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:03,348 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.672000000020489. input_tokens=9038, output_tokens=988
10:21:10,23 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:10,25 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.906999999890104. input_tokens=8438, output_tokens=742
10:21:10,644 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:10,647 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.422000000020489. input_tokens=9008, output_tokens=700
10:21:17,41 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:17,44 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.358999999938533. input_tokens=8350, output_tokens=873
10:21:27,331 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:27,453 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:27,457 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.312000000150874. input_tokens=3414, output_tokens=751
10:21:27,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.202999999979511. input_tokens=7230, output_tokens=752
10:21:30,780 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:30,785 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.625. input_tokens=8709, output_tokens=840
10:21:31,40 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:31,43 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.9689999998081475. input_tokens=7204, output_tokens=820
10:21:31,652 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:31,655 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 11.547000000020489. input_tokens=7688, output_tokens=1034
10:21:33,714 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:33,718 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.968999999808148. input_tokens=8323, output_tokens=1053
10:21:39,215 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:39,219 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.030999999959022. input_tokens=8750, output_tokens=913
10:21:43,324 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:43,327 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.515000000130385. input_tokens=7876, output_tokens=1076
10:21:46,47 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:46,51 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.875. input_tokens=7980, output_tokens=745
10:21:51,434 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:51,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.125. input_tokens=8531, output_tokens=741
10:21:53,815 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:21:53,819 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 13.780999999959022. input_tokens=9798, output_tokens=977
10:22:01,546 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:01,550 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.686999999918044. input_tokens=8748, output_tokens=749
10:22:06,256 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:06,260 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.343000000109896. input_tokens=8871, output_tokens=919
10:22:12,96 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:12,100 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.452999999979511. input_tokens=9018, output_tokens=859
10:22:12,800 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:12,803 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 9.280999999959022. input_tokens=8978, output_tokens=933
10:22:14,54 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:14,58 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 26.094000000040978. input_tokens=9904, output_tokens=986
10:22:15,471 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:15,474 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.5939999998081475. input_tokens=9908, output_tokens=858
10:22:20,86 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:20,446 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.405999999959022. input_tokens=9168, output_tokens=889
10:22:24,120 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:24,481 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.5780000002123415. input_tokens=8778, output_tokens=891
10:22:28,803 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:28,805 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.905999999959022. input_tokens=9325, output_tokens=983
10:22:31,997 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:31,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.968000000109896. input_tokens=8861, output_tokens=794
10:22:36,36 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:36,40 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.75. input_tokens=9501, output_tokens=825
10:22:43,2 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:43,6 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 10.140000000130385. input_tokens=9615, output_tokens=991
10:22:49,94 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:49,98 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.265999999828637. input_tokens=9570, output_tokens=791
10:22:49,344 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:49,345 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 12.343999999808148. input_tokens=9577, output_tokens=865
10:22:53,216 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:53,221 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.343999999808148. input_tokens=9172, output_tokens=1021
10:22:56,381 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:22:56,384 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.655999999959022. input_tokens=9623, output_tokens=743
10:23:01,469 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:23:01,472 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 8.422000000020489. input_tokens=9320, output_tokens=913
10:23:07,394 httpx INFO HTTP Request: POST https://eastus-openai-arash.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-02-15-preview "HTTP/1.1 200 OK"
10:23:07,396 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 7.140999999828637. input_tokens=9636, output_tokens=794
10:23:07,478 datashaper.workflow.workflow INFO executing verb window
10:23:07,485 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
10:23:07,864 graphrag.index.run INFO Running workflow: create_final_text_units...
10:23:07,864 graphrag.index.run INFO dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids']
10:23:07,865 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
10:23:07,892 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
10:23:07,913 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
10:23:08,1 datashaper.workflow.workflow INFO executing verb select
10:23:08,41 datashaper.workflow.workflow INFO executing verb rename
10:23:08,84 datashaper.workflow.workflow INFO executing verb join
10:23:08,129 datashaper.workflow.workflow INFO executing verb join
10:23:08,179 datashaper.workflow.workflow INFO executing verb aggregate_override
10:23:08,223 datashaper.workflow.workflow INFO executing verb select
10:23:08,227 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
10:23:08,516 graphrag.index.run INFO Running workflow: create_base_documents...
10:23:08,516 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
10:23:08,517 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
10:23:08,621 datashaper.workflow.workflow INFO executing verb unroll
10:23:08,670 datashaper.workflow.workflow INFO executing verb select
10:23:08,714 datashaper.workflow.workflow INFO executing verb rename
10:23:08,760 datashaper.workflow.workflow INFO executing verb join
10:23:08,810 datashaper.workflow.workflow INFO executing verb aggregate_override
10:23:08,854 datashaper.workflow.workflow INFO executing verb join
10:23:08,904 datashaper.workflow.workflow INFO executing verb rename
10:23:08,988 datashaper.workflow.workflow INFO executing verb convert
10:23:09,91 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
10:23:09,412 graphrag.index.run INFO Running workflow: create_final_documents...
10:23:09,412 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
10:23:09,413 graphrag.index.run INFO read table from storage: create_base_documents.parquet
10:23:09,509 datashaper.workflow.workflow INFO executing verb rename
10:23:09,523 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
